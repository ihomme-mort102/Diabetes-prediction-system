{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a853a9fe",
   "metadata": {},
   "source": [
    "# Diabetes Prediction Project\n",
    "This notebook implements **Week 1 (EDA & Cleaning)** and **Week 2 (Modeling & Evaluation)** for the NIDDK diabetes dataset.\n",
    "\n",
    "Dataset: `diabetes.csv`\n",
    "\n",
    "Steps:\n",
    "- Data exploration & visualization\n",
    "- Data cleaning & imputation\n",
    "- Class balance analysis\n",
    "- Scatter plots & correlations\n",
    "- Model building (KNN, Logistic Regression, Random Forest, XGBoost)\n",
    "- Model comparison & evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fdf6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Quick overview\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df['Outcome'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columns where 0 indicates missing values\n",
    "zero_missing_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# Replace zeros with NaN\n",
    "df[zero_missing_cols] = df[zero_missing_cols].replace(0, np.nan)\n",
    "\n",
    "# Count missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histograms for variables with missing values\n",
    "for col in zero_missing_cols:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.histplot(df[col].dropna(), kde=True)\n",
    "    plt.title(f\"Histogram of {col} (0s treated as missing)\")\n",
    "    plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Frequency plot of data types\n",
    "dtype_counts = df.dtypes.value_counts()\n",
    "plt.figure(figsize=(5,3))\n",
    "sns.barplot(x=dtype_counts.index.astype(str), y=dtype_counts.values)\n",
    "plt.title(\"Count of variable data types\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Data type\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8cab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outcome class balance\n",
    "sns.countplot(x='Outcome', data=df)\n",
    "plt.title(\"Outcome (0 = non-diabetic, 1 = diabetic)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f472af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pairwise scatter plots for selected variables\n",
    "sns.pairplot(df.dropna(subset=['Glucose','BMI','Age','Insulin']), \n",
    "             vars=['Glucose','BMI','Age','Insulin'], \n",
    "             hue='Outcome', plot_kws={'alpha':0.5, 's':30})\n",
    "plt.suptitle(\"Pairwise scatterplots (subset without missing)\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ab5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title(\"Correlation heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8054ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Median imputation\n",
    "df_imputed = df.copy()\n",
    "for col in zero_missing_cols:\n",
    "    median_val = df_imputed[col].median()\n",
    "    df_imputed[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Optional: Missing flag for Insulin\n",
    "df_imputed['Insulin_missing_flag'] = df['Insulin'].isnull().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e6244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare X, y\n",
    "X = df_imputed.drop(columns=['Outcome'])\n",
    "y = df_imputed['Outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Helper for specificity\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b99477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KNN baseline model\n",
    "pipe_knn = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
    "param_knn = {'knn__n_neighbors': [3,5,7,9,11,13,15], 'knn__weights': ['uniform','distance'], 'knn__p': [1,2]}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs_knn = GridSearchCV(pipe_knn, param_knn, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "gs_knn.fit(X_train, y_train)\n",
    "\n",
    "knn_best = gs_knn.best_estimator_\n",
    "y_pred_knn = knn_best.predict(X_test)\n",
    "y_proba_knn = knn_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Best KNN params:\", gs_knn.best_params_)\n",
    "print(\"KNN Test AUC:\", roc_auc_score(y_test, y_proba_knn))\n",
    "print(\"KNN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "print(\"KNN Specificity:\", specificity_score(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "pipe_log = Pipeline([('scaler', StandardScaler()), ('log', LogisticRegression(max_iter=1000, solver='liblinear'))])\n",
    "param_log = {'log__C': [0.01, 0.1, 1, 10, 100], 'log__penalty': ['l1','l2']}\n",
    "gs_log = GridSearchCV(pipe_log, param_log, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "gs_log.fit(X_train, y_train)\n",
    "\n",
    "best_log = gs_log.best_estimator_\n",
    "y_pred_log = best_log.predict(X_test)\n",
    "y_proba_log = best_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Best Logistic Regression params:\", gs_log.best_params_)\n",
    "print(\"Logistic Regression Test AUC:\", roc_auc_score(y_test, y_proba_log))\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_log))\n",
    "print(\"Logistic Regression Specificity:\", specificity_score(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cf541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest\n",
    "pipe_rf = Pipeline([('rf', RandomForestClassifier(random_state=42))])\n",
    "param_rf = {'rf__n_estimators':[100,200], 'rf__max_depth':[None,5,8,12], 'rf__min_samples_split':[2,5,10]}\n",
    "gs_rf = GridSearchCV(pipe_rf, param_rf, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf = gs_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_proba_rf = best_rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Best RF params:\", gs_rf.best_params_)\n",
    "print(\"Random Forest Test AUC:\", roc_auc_score(y_test, y_proba_rf))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest Specificity:\", specificity_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022bac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ROC Curve comparison\n",
    "plt.figure(figsize=(6,5))\n",
    "for name, proba in [('KNN', y_proba_knn), ('Logistic', y_proba_log), ('RF', y_proba_rf)]:\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc_score(y_test, proba):.3f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
